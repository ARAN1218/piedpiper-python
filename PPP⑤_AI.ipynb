{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nJDqGqKVX40l",
        "-E-SWqyEgCaO",
        "utNfEbJRgIun",
        "Esh72kSbgkHQ",
        "Wl_TJMeS9KDT",
        "yVpenQQAKoAy",
        "zTLcPST1sv34",
        "xF29qepg9GkS"
      ],
      "authorship_tag": "ABX9TyMA1P1oe484aJ5JhH6KhxBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARAN1218/piedpiper-python/blob/main/PPP%E2%91%A4_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJDqGqKVX40l"
      },
      "source": [
        "# 人工知能 ~人類最悪にして最後の発明~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E-SWqyEgCaO"
      },
      "source": [
        "## 早速やっていこう！...あれ？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xgLKvGAXwyL"
      },
      "source": [
        "# 外部ライブラリを召喚(インポート)しよう→pyファイルをインストールしている\n",
        "# ライブラリをインポートする際は(特にノートブック形式だと)最初の段階で分析に使うライブラリを全部インポートする慣習がある\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.datasets import load_boston"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrqlwMjaY9kZ"
      },
      "source": [
        "# ライブラリを使って簡単にデータをダウンロードしてみよう\n",
        "boston = load_boston()\n",
        "boston_data = boston.data\n",
        "columns_name = boston.feature_names\n",
        "df = pd.DataFrame(boston_data, columns=columns_name)\n",
        "display(df)\n",
        "# 何かこのデータセットは倫理的な問題があるとかで将来的に廃止するそうです"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utNfEbJRgIun"
      },
      "source": [
        "## じゃあ別のデータセットでやろうか"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFN_nCo7bdED"
      },
      "source": [
        "# 警告文に記載されている推奨ライブラリをインポート\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# ライブラリを用いて、説明変数(予測の材料)を簡単にロードする\n",
        "housing_data = housing.data\n",
        "housing_data_names = housing.feature_names\n",
        "df_data = pd.DataFrame(housing_data, columns=housing_data_names)\n",
        "\n",
        "# 目的変数(予測対象)も簡単にロードできる\n",
        "housing_target = housing.target\n",
        "housing_target_names = housing.target_names\n",
        "df_target = pd.DataFrame(housing_target, columns=housing_target_names)\n",
        "\n",
        "# 作成したデータフレームを見てみる\n",
        "display(df_data)\n",
        "display(df_target)\n",
        "\n",
        "# 説明変数と目的変数のデータフレームを結合する\n",
        "df = pd.concat([df_data, df_target], axis=1)\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PflvXCsldv9J"
      },
      "source": [
        "### 説明変数の意味\n",
        "\n",
        "\n",
        "MedInc：ブロックグループの収入の中央値\n",
        "\n",
        "HouseAge：ブロックグループの築年数の中央値\n",
        "\n",
        "AveRooms：1世帯あたりの平均部屋数\n",
        "\n",
        "AveBedrms：1世帯あたりの平均寝室数\n",
        "\n",
        "Population：ブロックグループの人口\n",
        "\n",
        "AveOccup：平均世帯員数\n",
        "\n",
        "Latitude：ブロックグループの緯度\n",
        "\n",
        "Longitude：ブロックグループの経度\n",
        "\n",
        "### 目的変数の意味\n",
        "\n",
        "MedHouseVal：対象ブロックの住宅価格の中央値"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esh72kSbgkHQ"
      },
      "source": [
        "## 早速機械学習...する前に"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63XTKKGfQXK"
      },
      "source": [
        "# データを可視化して、目的変数と説明変数の関係を分析しよう\n",
        "# データの特性も分からないのにいきなり機械学習モデル作るのは愚か極まりない\n",
        "\n",
        "def scatter(data):\n",
        "  for data_name in housing.feature_names:\n",
        "    plt.title(data_name + \" vs. MedHouseVal\")\n",
        "    plt.xlabel(data_name)\n",
        "    plt.ylabel('MedHouseVal')\n",
        "    plt.scatter(df[data_name], df['MedHouseVal']) # plt.scatter(x, y)\n",
        "    plt.show()\n",
        "    print('相関係数：',np.corrcoef(df[data_name], df['MedHouseVal'])[0][1])\n",
        "\n",
        "scatter(df) # 散布図からどんな関係があるかを考えてみよう！"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkWMoTy1mifW"
      },
      "source": [
        "# 上記の作業はseabornライブラリを用いて2行で実現できる\n",
        "# →有用なライブラリを検索して活用する能力も必要！\n",
        "sns.pairplot(df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddTZsqqP-d5V"
      },
      "source": [
        "# ヒートマップ作成も一行で完結\n",
        "sns.heatmap(df.corr())\n",
        "plt.show()\n",
        "\n",
        "# 各種引数で調整可\n",
        "sns.heatmap(df.corr(), annot=True, fmt=\"1.1f\", cmap='Oranges')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl_TJMeS9KDT"
      },
      "source": [
        "## まずは単回帰分析から"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzSqGZVX9F6K"
      },
      "source": [
        "# データセットを学習データとテストデータに分ける→モデルの評価に使うため！\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_MedInc = df_data[['MedInc']] # MedIncカラムだけ取り出す\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_MedInc, df_target, shuffle=True, random_state=71)\n",
        "\n",
        "\n",
        "# 機械学習ライブラリをインポート\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 機械学習モデルのインスタンスを生成\n",
        "model = LinearRegression()\n",
        "\n",
        "# モデルを学習させる\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# テストデータを使って、モデルに予測させる\n",
        "pred = model.predict(x_test)\n",
        "\n",
        "# 予測結果を出力させる\n",
        "df_pred = pd.DataFrame(pred, columns=['pred'])\n",
        "df_true = y_test.reset_index(drop=True).rename(columns={'MedHouseVal': 'true'})\n",
        "df = pd.concat([df_pred, df_true], axis=1)\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig4CB0cACjaM"
      },
      "source": [
        "# モデルの評価を行うため、MAE/RMSE/R^2の計算と残差プロットを行う\n",
        "\n",
        "# MAE/RMSE/R^2の計算\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"MAE:\", mean_absolute_error(df['true'], df['pred'])) # 平均絶対誤差...小さい程良い\n",
        "print(\"RMSE:\", np.sqrt(mean_absolute_error(df['true'], df['pred']))) # 平均平方二乗誤差...小さい程良い\n",
        "print(\"R^2:\", model.score(x_train, y_train)) # 決定係数...大きい程良い\n",
        "\n",
        "# 傾きと切片を見てみる\n",
        "print('傾き(回帰係数) = ', model.coef_[0])\n",
        "print('切片 = ', model.intercept_)\n",
        "\n",
        "# 残差プロット...予測値と真の値がどれだけ離れているかを可視化\n",
        "plt.scatter(df['pred'], df['pred'] - df['true'], c='green', marker='s', label='Test Data')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.legend(loc='upper left')\n",
        "plt.hlines(y=0, xmin=-10, xmax=20, lw=2, color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVpenQQAKoAy"
      },
      "source": [
        "## お待ちかねの多変量解析(重回帰分析)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqdcFO-xrqxJ"
      },
      "source": [
        "# 次は全部の変数をぶち込んでみる\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_data, df_target, shuffle=True, random_state=71)\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "pred = model.predict(x_test)\n",
        "df_pred = pd.DataFrame(pred, columns=['pred'])\n",
        "df_true = y_test.reset_index(drop=True).rename(columns={'MedHouseVal': 'true'})\n",
        "df = pd.concat([df_pred, df_true], axis=1)\n",
        "display(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQRdifgQud9I"
      },
      "source": [
        "# MAE/RMSE/R^2の計算\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"MAE:\", mean_absolute_error(df['true'], df['pred']))\n",
        "print(\"RMSE:\", np.sqrt(mean_absolute_error(df['true'], df['pred'])))\n",
        "print(\"R^2:\", model.score(x_train, y_train))\n",
        "\n",
        "# 傾きと切片を見てみる\n",
        "print('傾き(偏回帰係数) = ', model.coef_[0]) # 説明変数の係数を出力\n",
        "print('切片 = ', model.intercept_)\n",
        "\n",
        "# 残差プロット\n",
        "plt.scatter(df['pred'], df['pred'] - df['true'], c='green', marker='s', label='Test Data')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.legend(loc='upper left')\n",
        "plt.hlines(y=0, xmin=-10, xmax=20, lw=2, color='red')\n",
        "plt.show()\n",
        "\n",
        "# ちょっとだけ当てはまりが良くなった→モデルが複雑（説明変数が多い）だとモデルの性能が（一般的に）良くなる"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 重回帰分析の問題点"
      ],
      "metadata": {
        "id": "zTLcPST1sv34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 偏相関係数\n",
        " - 重回帰分析で説明変数として採用する変数の評価に用いる。\n",
        "- 自由度調整済み重相関係数\n",
        " - 単回帰分析モデルと重回帰分析モデルをそのまま比較するのは不公平！→自由度（=学習に用いた説明変数の数）で調整してフェアな比較をする。\n",
        "- 多重共線性\n",
        " - 偏回帰係数の値に極端な補正がかかってしまい、分析として適さないモデルができてしまう。\n",
        " - 説明変数同士で相関が高いと発生するので、相関の高い説明変数のペアが確認された場合にはそのどちらかだけを採用することで回避できる。\n",
        " - もしくはVIF(Variance Inflation Factors)を計算し、その値が10以下の説明変数だけを採用すれば良い！ \n",
        "- 残差分析\n",
        " - 外れ値や異常値を確認し、隠れた因子を考慮する\n",
        " - データの傾向から、分散の均質性や非線形性を確認する。\n",
        "- 変数選択法\n",
        " - 全ての説明変数の組み合わせを分析するのは大変なので、回帰係数の選別をする。\n",
        " - 情報量基準等を調べてみましょー🐦\n",
        "- ダミー変数\n",
        " - 質的変数(男女等)を重回帰分析に組み込むためには、質的変数を数値に変換する必要がある。\n",
        " - 例えば、男：０、女：１として変換すると、男女の区別をつけながらその影響を分析することができる！"
      ],
      "metadata": {
        "id": "aiFlGRPAfhyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Webデータ分析実践"
      ],
      "metadata": {
        "id": "xF29qepg9GkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 気象庁のWebサイトから気象データを取ってくる(これをスクレイピングと言います)\n",
        "url = \"https://www.data.jma.go.jp/obd/stats/etrn/view/daily_s1.php?prec_no=46&block_no=47670&year=2022&month=1&day=1&view=\"\n",
        "df_weather = pd.read_html(url, header = 0)\n",
        "df_weather"
      ],
      "metadata": {
        "id": "AD984rpVgigW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# リストにしまわれているので、一個にする\n",
        "df_weather = df_weather[0]\n",
        "df_weather.head(10)\n",
        "# 汚ねぇ！！→分析に使えるデータに直します"
      ],
      "metadata": {
        "id": "Z6b127ezg1q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 日本語の行を削る\n",
        "df_weather = df_weather.drop(index=df.index[[0,1,2]])\n",
        "df_weather.head(5)"
      ],
      "metadata": {
        "id": "bicWNmu8h1VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データ型を確認\n",
        "df_weather.dtypes\n",
        "# 汚ねぇ！！！→数値に直す"
      ],
      "metadata": {
        "id": "Ura2aIpujfYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 今回は説明変数を平均湿度、目的変数を平均気温にして単回帰分析してみる\n",
        "# 小数が多いので、float型に直す\n",
        "df_weather = df_weather[['湿度(％)', '気温(℃)']]\n",
        "df_weather['湿度(％)'] = df_weather['湿度(％)'].astype(float)\n",
        "df_weather['気温(℃)'] = df_weather['気温(℃)'].astype(float)\n",
        "df_weather.dtypes"
      ],
      "metadata": {
        "id": "6RHdjDXUjszq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 単回帰分析をする\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_x = df_weather[['湿度(％)']]\n",
        "df_y = df_weather[['気温(℃)']]\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, shuffle=True, random_state=71)\n",
        "\n",
        "\n",
        "# 機械学習ライブラリをインポート\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 機械学習モデルのインスタンスを生成\n",
        "model = LinearRegression()\n",
        "\n",
        "# モデルを学習させる\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# テストデータを使って、モデルに予測させる\n",
        "pred = model.predict(x_test)\n",
        "\n",
        "# 予測結果を出力させる\n",
        "df_pred = pd.DataFrame(pred, columns=['pred'])\n",
        "df_true = y_test.reset_index(drop=True).rename(columns={'気温(℃)': 'true'})\n",
        "df = pd.concat([df_pred, df_true], axis=1)\n",
        "display(df)"
      ],
      "metadata": {
        "id": "lXULbO-slEHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの評価を行うため、MAE/RMSE/R^2の計算と残差プロットを行う\n",
        "\n",
        "# MAE/RMSE/R^2の計算\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"MAE:\", mean_absolute_error(df['true'], df['pred'])) # 平均絶対誤差...小さい程良い\n",
        "print(\"RMSE:\", np.sqrt(mean_absolute_error(df['true'], df['pred']))) # 平均平方二乗誤差...小さい程良い\n",
        "print(\"R^2:\", model.score(x_train, y_train)) # 決定係数...大きい程良い\n",
        "\n",
        "# 傾きと切片を見てみる\n",
        "print('傾き(回帰係数) = ', model.coef_[0])\n",
        "print('切片 = ', model.intercept_)\n",
        "\n",
        "# 残差プロット...予測値と真の値がどれだけ離れているかを可視化\n",
        "plt.scatter(df['pred'], df['pred'] - df['true'], c='green', marker='s', label='Test Data')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.legend(loc='upper left')\n",
        "plt.hlines(y=0, xmin=-10, xmax=20, lw=2, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JV2U2Iefl6EB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}